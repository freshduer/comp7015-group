==========================================
DistilBert training test (RTX 4090)
==========================================
Job ID: 4283
Node: gpu10
GPU: 1
Working directory: /home/comp/zhanzhao/comp7015-group/bert
==========================================
transformers/datasets ready. torch cuda: True
Raw splits ready. Train/Val/Test = 20000 2500 2500
{'loss': 0.6947, 'grad_norm': 1.5899767875671387, 'learning_rate': 2.6133333333333334e-06, 'epoch': 0.04}
{'loss': 0.6857, 'grad_norm': 2.1343443393707275, 'learning_rate': 5.28e-06, 'epoch': 0.08}
{'loss': 0.6319, 'grad_norm': 2.65360951423645, 'learning_rate': 7.946666666666666e-06, 'epoch': 0.12}
{'loss': 0.4257, 'grad_norm': 6.618755340576172, 'learning_rate': 1.0613333333333334e-05, 'epoch': 0.16}
{'loss': 0.3677, 'grad_norm': 1.74257493019104, 'learning_rate': 1.3280000000000002e-05, 'epoch': 0.2}
{'loss': 0.2936, 'grad_norm': 3.9736602306365967, 'learning_rate': 1.5946666666666668e-05, 'epoch': 0.24}
{'loss': 0.2809, 'grad_norm': 6.773561477661133, 'learning_rate': 1.8613333333333334e-05, 'epoch': 0.28}
{'loss': 0.3164, 'grad_norm': 8.8892183303833, 'learning_rate': 1.985777777777778e-05, 'epoch': 0.32}
{'loss': 0.3375, 'grad_norm': 2.8609867095947266, 'learning_rate': 1.9561481481481483e-05, 'epoch': 0.36}
{'loss': 0.3371, 'grad_norm': 3.6028993129730225, 'learning_rate': 1.9265185185185186e-05, 'epoch': 0.4}
{'loss': 0.3059, 'grad_norm': 12.971959114074707, 'learning_rate': 1.896888888888889e-05, 'epoch': 0.44}
{'loss': 0.2597, 'grad_norm': 0.3784915506839752, 'learning_rate': 1.8672592592592594e-05, 'epoch': 0.48}
{'loss': 0.2903, 'grad_norm': 4.2540459632873535, 'learning_rate': 1.83762962962963e-05, 'epoch': 0.52}
{'loss': 0.2852, 'grad_norm': 2.9951155185699463, 'learning_rate': 1.8080000000000003e-05, 'epoch': 0.56}
{'loss': 0.2854, 'grad_norm': 0.9546393752098083, 'learning_rate': 1.7783703703703706e-05, 'epoch': 0.6}
{'loss': 0.261, 'grad_norm': 1.0105801820755005, 'learning_rate': 1.748740740740741e-05, 'epoch': 0.64}
{'loss': 0.2654, 'grad_norm': 6.566658973693848, 'learning_rate': 1.719111111111111e-05, 'epoch': 0.68}
{'loss': 0.2732, 'grad_norm': 0.9164553284645081, 'learning_rate': 1.6894814814814817e-05, 'epoch': 0.72}
{'loss': 0.2763, 'grad_norm': 4.5200018882751465, 'learning_rate': 1.659851851851852e-05, 'epoch': 0.76}
{'loss': 0.2413, 'grad_norm': 11.01888370513916, 'learning_rate': 1.6302222222222222e-05, 'epoch': 0.8}
{'loss': 0.2997, 'grad_norm': 9.699756622314453, 'learning_rate': 1.600592592592593e-05, 'epoch': 0.84}
{'loss': 0.2839, 'grad_norm': 6.542644500732422, 'learning_rate': 1.570962962962963e-05, 'epoch': 0.88}
{'loss': 0.2653, 'grad_norm': 0.4678206145763397, 'learning_rate': 1.5413333333333337e-05, 'epoch': 0.92}
{'loss': 0.2803, 'grad_norm': 9.91655158996582, 'learning_rate': 1.511703703703704e-05, 'epoch': 0.96}
{'loss': 0.2909, 'grad_norm': 6.922738075256348, 'learning_rate': 1.4820740740740742e-05, 'epoch': 1.0}
{'eval_loss': 0.2902711033821106, 'eval_accuracy': 0.8992, 'eval_f1': 0.8968903436988543, 'eval_runtime': 5.0416, 'eval_samples_per_second': 495.879, 'eval_steps_per_second': 15.67, 'epoch': 1.0}
{'loss': 0.2242, 'grad_norm': 2.186163902282715, 'learning_rate': 1.4524444444444445e-05, 'epoch': 1.04}
{'loss': 0.1875, 'grad_norm': 1.3395581245422363, 'learning_rate': 1.422814814814815e-05, 'epoch': 1.08}
{'loss': 0.2092, 'grad_norm': 16.463464736938477, 'learning_rate': 1.3931851851851852e-05, 'epoch': 1.12}
{'loss': 0.1904, 'grad_norm': 0.1690339744091034, 'learning_rate': 1.3635555555555558e-05, 'epoch': 1.16}
{'loss': 0.1968, 'grad_norm': 12.900272369384766, 'learning_rate': 1.333925925925926e-05, 'epoch': 1.2}
{'loss': 0.1255, 'grad_norm': 0.0795973539352417, 'learning_rate': 1.3042962962962963e-05, 'epoch': 1.24}
{'loss': 0.2383, 'grad_norm': 4.91347074508667, 'learning_rate': 1.2746666666666668e-05, 'epoch': 1.28}
{'loss': 0.2043, 'grad_norm': 11.091207504272461, 'learning_rate': 1.245037037037037e-05, 'epoch': 1.32}
{'loss': 0.1906, 'grad_norm': 0.11769420653581619, 'learning_rate': 1.2154074074074076e-05, 'epoch': 1.36}
{'loss': 0.1843, 'grad_norm': 6.560433387756348, 'learning_rate': 1.1857777777777779e-05, 'epoch': 1.4}
{'loss': 0.1891, 'grad_norm': 7.43698263168335, 'learning_rate': 1.1561481481481482e-05, 'epoch': 1.44}
{'loss': 0.2028, 'grad_norm': 2.613311529159546, 'learning_rate': 1.1265185185185186e-05, 'epoch': 1.48}
{'loss': 0.1877, 'grad_norm': 8.141692161560059, 'learning_rate': 1.0968888888888889e-05, 'epoch': 1.52}
{'loss': 0.1865, 'grad_norm': 10.419349670410156, 'learning_rate': 1.0672592592592595e-05, 'epoch': 1.56}
{'loss': 0.1977, 'grad_norm': 1.4756224155426025, 'learning_rate': 1.0376296296296297e-05, 'epoch': 1.6}
{'loss': 0.1873, 'grad_norm': 11.878857612609863, 'learning_rate': 1.008e-05, 'epoch': 1.64}
{'loss': 0.2257, 'grad_norm': 1.8687293529510498, 'learning_rate': 9.783703703703704e-06, 'epoch': 1.68}
{'loss': 0.1919, 'grad_norm': 4.574530124664307, 'learning_rate': 9.487407407407409e-06, 'epoch': 1.72}
{'loss': 0.1634, 'grad_norm': 0.4965648949146271, 'learning_rate': 9.191111111111111e-06, 'epoch': 1.76}
{'loss': 0.1768, 'grad_norm': 0.8300889134407043, 'learning_rate': 8.894814814814816e-06, 'epoch': 1.8}
{'loss': 0.2259, 'grad_norm': 5.392175674438477, 'learning_rate': 8.59851851851852e-06, 'epoch': 1.84}
{'loss': 0.2144, 'grad_norm': 3.5079400539398193, 'learning_rate': 8.302222222222223e-06, 'epoch': 1.88}
{'loss': 0.195, 'grad_norm': 2.232649803161621, 'learning_rate': 8.005925925925927e-06, 'epoch': 1.92}
{'loss': 0.1374, 'grad_norm': 6.103194236755371, 'learning_rate': 7.70962962962963e-06, 'epoch': 1.96}
{'loss': 0.2066, 'grad_norm': 0.23042604327201843, 'learning_rate': 7.413333333333333e-06, 'epoch': 2.0}
{'eval_loss': 0.2697194814682007, 'eval_accuracy': 0.9168, 'eval_f1': 0.9169329073482428, 'eval_runtime': 4.8943, 'eval_samples_per_second': 510.795, 'eval_steps_per_second': 16.141, 'epoch': 2.0}
{'loss': 0.0853, 'grad_norm': 2.189379930496216, 'learning_rate': 7.1170370370370376e-06, 'epoch': 2.04}
{'loss': 0.1365, 'grad_norm': 20.973594665527344, 'learning_rate': 6.820740740740741e-06, 'epoch': 2.08}
{'loss': 0.0919, 'grad_norm': 0.2837711572647095, 'learning_rate': 6.524444444444445e-06, 'epoch': 2.12}
{'loss': 0.0981, 'grad_norm': 3.406580924987793, 'learning_rate': 6.228148148148149e-06, 'epoch': 2.16}
{'loss': 0.0926, 'grad_norm': 0.4104854464530945, 'learning_rate': 5.9318518518518516e-06, 'epoch': 2.2}
{'loss': 0.1223, 'grad_norm': 8.792597770690918, 'learning_rate': 5.635555555555557e-06, 'epoch': 2.24}
{'loss': 0.1228, 'grad_norm': 0.46724846959114075, 'learning_rate': 5.339259259259259e-06, 'epoch': 2.28}
{'loss': 0.1104, 'grad_norm': 0.18172597885131836, 'learning_rate': 5.042962962962963e-06, 'epoch': 2.32}
{'loss': 0.1233, 'grad_norm': 7.864560127258301, 'learning_rate': 4.746666666666667e-06, 'epoch': 2.36}
{'loss': 0.1356, 'grad_norm': 0.07090901583433151, 'learning_rate': 4.450370370370371e-06, 'epoch': 2.4}
{'loss': 0.116, 'grad_norm': 0.2601006031036377, 'learning_rate': 4.154074074074074e-06, 'epoch': 2.44}
{'loss': 0.1023, 'grad_norm': 0.04889091104269028, 'learning_rate': 3.857777777777778e-06, 'epoch': 2.48}
{'loss': 0.1019, 'grad_norm': 8.907532691955566, 'learning_rate': 3.561481481481482e-06, 'epoch': 2.52}
{'loss': 0.1204, 'grad_norm': 0.5280501842498779, 'learning_rate': 3.2651851851851856e-06, 'epoch': 2.56}
{'loss': 0.1123, 'grad_norm': 0.0585152693092823, 'learning_rate': 2.968888888888889e-06, 'epoch': 2.6}
{'loss': 0.1036, 'grad_norm': 0.326731413602829, 'learning_rate': 2.6725925925925926e-06, 'epoch': 2.64}
{'loss': 0.0943, 'grad_norm': 7.372910022735596, 'learning_rate': 2.3762962962962965e-06, 'epoch': 2.68}
{'loss': 0.153, 'grad_norm': 0.04053865373134613, 'learning_rate': 2.08e-06, 'epoch': 2.72}
{'loss': 0.087, 'grad_norm': 0.07956095039844513, 'learning_rate': 1.783703703703704e-06, 'epoch': 2.76}
{'loss': 0.0607, 'grad_norm': 0.050763774663209915, 'learning_rate': 1.4874074074074074e-06, 'epoch': 2.8}
{'loss': 0.1045, 'grad_norm': 4.964056015014648, 'learning_rate': 1.1911111111111111e-06, 'epoch': 2.84}
{'loss': 0.1341, 'grad_norm': 0.05381709709763527, 'learning_rate': 8.948148148148149e-07, 'epoch': 2.88}
{'loss': 0.0953, 'grad_norm': 7.311892986297607, 'learning_rate': 5.985185185185185e-07, 'epoch': 2.92}
{'loss': 0.0968, 'grad_norm': 3.527989149093628, 'learning_rate': 3.0222222222222225e-07, 'epoch': 2.96}
{'loss': 0.1215, 'grad_norm': 10.88703727722168, 'learning_rate': 5.9259259259259265e-09, 'epoch': 3.0}
{'eval_loss': 0.3470728099346161, 'eval_accuracy': 0.9144, 'eval_f1': 0.9135702746365105, 'eval_runtime': 4.924, 'eval_samples_per_second': 507.722, 'eval_steps_per_second': 16.044, 'epoch': 3.0}
{'train_runtime': 557.6241, 'train_samples_per_second': 107.599, 'train_steps_per_second': 6.725, 'train_loss': 0.21462791531880696, 'epoch': 3.0}
Val metrics: {'eval_loss': 0.2697267234325409, 'eval_accuracy': 0.9168, 'eval_f1': 0.9169329073482428, 'eval_runtime': 4.9627, 'eval_samples_per_second': 503.762, 'eval_steps_per_second': 15.919, 'epoch': 3.0}
Test metrics: {'eval_loss': 0.2963772714138031, 'eval_accuracy': 0.9048, 'eval_f1': 0.9049520766773163, 'eval_runtime': 4.7628, 'eval_samples_per_second': 524.9, 'eval_steps_per_second': 16.587, 'epoch': 3.0}
Evaluation metrics saved to: /home/comp/zhanzhao/comp7015-group/bert/result/distilbert-base-uncased-20251120-121844.json
Total epochs recorded: 3
Training completed!
Validation accuracy: 0.9168
Test accuracy: 0.9048
==========================================
DistilBert training test completed!
==========================================
