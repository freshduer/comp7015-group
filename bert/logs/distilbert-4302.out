==========================================
DistilBert training test (RTX 4090)
==========================================
Job ID: 4302
Node: gpu10
GPU: 1
Working directory: /home/comp/zhanzhao/comp7015-group/bert
==========================================
transformers/datasets ready. torch cuda: True
Raw splits ready. Train/Val/Test = 20000 2500 2500
{'loss': 0.6929, 'grad_norm': 1.5553995370864868, 'learning_rate': 6.533333333333333e-06, 'epoch': 0.04}
{'loss': 0.6541, 'grad_norm': 2.9753618240356445, 'learning_rate': 1.32e-05, 'epoch': 0.08}
{'loss': 0.3986, 'grad_norm': 9.28508472442627, 'learning_rate': 1.9866666666666667e-05, 'epoch': 0.12}
{'loss': 0.3564, 'grad_norm': 10.960375785827637, 'learning_rate': 2.6533333333333332e-05, 'epoch': 0.16}
{'loss': 0.379, 'grad_norm': 7.038325309753418, 'learning_rate': 3.32e-05, 'epoch': 0.2}
{'loss': 0.3313, 'grad_norm': 9.577152252197266, 'learning_rate': 3.986666666666667e-05, 'epoch': 0.24}
{'loss': 0.3125, 'grad_norm': 4.090096950531006, 'learning_rate': 4.653333333333334e-05, 'epoch': 0.28}
{'loss': 0.3586, 'grad_norm': 8.39376449584961, 'learning_rate': 4.964444444444445e-05, 'epoch': 0.32}
{'loss': 0.391, 'grad_norm': 8.340465545654297, 'learning_rate': 4.890370370370371e-05, 'epoch': 0.36}
{'loss': 0.341, 'grad_norm': 4.33825159072876, 'learning_rate': 4.816296296296297e-05, 'epoch': 0.4}
{'loss': 0.3302, 'grad_norm': 12.467405319213867, 'learning_rate': 4.7422222222222226e-05, 'epoch': 0.44}
{'loss': 0.2793, 'grad_norm': 0.1686219573020935, 'learning_rate': 4.6681481481481484e-05, 'epoch': 0.48}
{'loss': 0.3256, 'grad_norm': 3.1762449741363525, 'learning_rate': 4.594074074074074e-05, 'epoch': 0.52}
{'loss': 0.3113, 'grad_norm': 3.023409605026245, 'learning_rate': 4.52e-05, 'epoch': 0.56}
{'loss': 0.2892, 'grad_norm': 1.3832498788833618, 'learning_rate': 4.445925925925926e-05, 'epoch': 0.6}
{'loss': 0.2929, 'grad_norm': 7.0295257568359375, 'learning_rate': 4.371851851851852e-05, 'epoch': 0.64}
{'loss': 0.2793, 'grad_norm': 7.316161155700684, 'learning_rate': 4.2977777777777776e-05, 'epoch': 0.68}
{'loss': 0.2971, 'grad_norm': 0.9026060700416565, 'learning_rate': 4.223703703703704e-05, 'epoch': 0.72}
{'loss': 0.318, 'grad_norm': 4.744821071624756, 'learning_rate': 4.14962962962963e-05, 'epoch': 0.76}
{'loss': 0.2585, 'grad_norm': 9.321998596191406, 'learning_rate': 4.075555555555556e-05, 'epoch': 0.8}
{'loss': 0.3122, 'grad_norm': 2.2297773361206055, 'learning_rate': 4.0014814814814816e-05, 'epoch': 0.84}
{'loss': 0.3052, 'grad_norm': 5.43031120300293, 'learning_rate': 3.9274074074074074e-05, 'epoch': 0.88}
{'loss': 0.2869, 'grad_norm': 0.4076414406299591, 'learning_rate': 3.853333333333334e-05, 'epoch': 0.92}
{'loss': 0.314, 'grad_norm': 3.4199609756469727, 'learning_rate': 3.77925925925926e-05, 'epoch': 0.96}
{'loss': 0.2872, 'grad_norm': 9.618399620056152, 'learning_rate': 3.7051851851851856e-05, 'epoch': 1.0}
{'eval_loss': 0.313525527715683, 'eval_accuracy': 0.9076, 'eval_f1': 0.9066666666666666, 'eval_runtime': 4.976, 'eval_samples_per_second': 502.416, 'eval_steps_per_second': 15.876, 'epoch': 1.0}
{'loss': 0.1997, 'grad_norm': 4.385226726531982, 'learning_rate': 3.6311111111111114e-05, 'epoch': 1.04}
{'loss': 0.2085, 'grad_norm': 2.7778353691101074, 'learning_rate': 3.557037037037037e-05, 'epoch': 1.08}
{'loss': 0.1972, 'grad_norm': 8.731428146362305, 'learning_rate': 3.482962962962963e-05, 'epoch': 1.12}
{'loss': 0.1816, 'grad_norm': 0.30607113242149353, 'learning_rate': 3.408888888888889e-05, 'epoch': 1.16}
{'loss': 0.1866, 'grad_norm': 7.886414527893066, 'learning_rate': 3.334814814814815e-05, 'epoch': 1.2}
{'loss': 0.114, 'grad_norm': 0.041864797472953796, 'learning_rate': 3.2607407407407406e-05, 'epoch': 1.24}
{'loss': 0.2021, 'grad_norm': 2.5584263801574707, 'learning_rate': 3.1866666666666664e-05, 'epoch': 1.28}
{'loss': 0.1853, 'grad_norm': 1.539452314376831, 'learning_rate': 3.112592592592592e-05, 'epoch': 1.32}
{'loss': 0.1487, 'grad_norm': 0.473163366317749, 'learning_rate': 3.0385185185185188e-05, 'epoch': 1.36}
{'loss': 0.1972, 'grad_norm': 5.340057849884033, 'learning_rate': 2.9644444444444446e-05, 'epoch': 1.4}
{'loss': 0.1963, 'grad_norm': 2.933528423309326, 'learning_rate': 2.8903703703703704e-05, 'epoch': 1.44}
{'loss': 0.2032, 'grad_norm': 0.47018659114837646, 'learning_rate': 2.8162962962962963e-05, 'epoch': 1.48}
{'loss': 0.1509, 'grad_norm': 3.177574634552002, 'learning_rate': 2.742222222222222e-05, 'epoch': 1.52}
{'loss': 0.1606, 'grad_norm': 10.147074699401855, 'learning_rate': 2.6681481481481486e-05, 'epoch': 1.56}
{'loss': 0.1875, 'grad_norm': 3.6131889820098877, 'learning_rate': 2.5940740740740744e-05, 'epoch': 1.6}
{'loss': 0.147, 'grad_norm': 4.433798313140869, 'learning_rate': 2.5200000000000003e-05, 'epoch': 1.64}
{'loss': 0.2069, 'grad_norm': 11.70104694366455, 'learning_rate': 2.445925925925926e-05, 'epoch': 1.68}
{'loss': 0.1543, 'grad_norm': 0.2257872372865677, 'learning_rate': 2.371851851851852e-05, 'epoch': 1.72}
{'loss': 0.1657, 'grad_norm': 1.4115681648254395, 'learning_rate': 2.2977777777777778e-05, 'epoch': 1.76}
{'loss': 0.1494, 'grad_norm': 0.2534325420856476, 'learning_rate': 2.2237037037037036e-05, 'epoch': 1.8}
{'loss': 0.1848, 'grad_norm': 3.132124185562134, 'learning_rate': 2.1496296296296298e-05, 'epoch': 1.84}
{'loss': 0.168, 'grad_norm': 2.820399045944214, 'learning_rate': 2.0755555555555556e-05, 'epoch': 1.88}
{'loss': 0.2081, 'grad_norm': 0.5549321174621582, 'learning_rate': 2.0014814814814818e-05, 'epoch': 1.92}
{'loss': 0.1339, 'grad_norm': 5.964903354644775, 'learning_rate': 1.9274074074074076e-05, 'epoch': 1.96}
{'loss': 0.2027, 'grad_norm': 0.4687073528766632, 'learning_rate': 1.8533333333333334e-05, 'epoch': 2.0}
{'eval_loss': 0.2858799397945404, 'eval_accuracy': 0.9076, 'eval_f1': 0.9087317265902806, 'eval_runtime': 4.7357, 'eval_samples_per_second': 527.902, 'eval_steps_per_second': 16.682, 'epoch': 2.0}
{'loss': 0.0622, 'grad_norm': 0.3516940772533417, 'learning_rate': 1.7792592592592593e-05, 'epoch': 2.04}
{'loss': 0.0727, 'grad_norm': 0.5960789322853088, 'learning_rate': 1.705185185185185e-05, 'epoch': 2.08}
{'loss': 0.0584, 'grad_norm': 0.10562928766012192, 'learning_rate': 1.6311111111111113e-05, 'epoch': 2.12}
{'loss': 0.069, 'grad_norm': 1.8396401405334473, 'learning_rate': 1.557037037037037e-05, 'epoch': 2.16}
{'loss': 0.0861, 'grad_norm': 0.38641324639320374, 'learning_rate': 1.482962962962963e-05, 'epoch': 2.2}
{'loss': 0.0752, 'grad_norm': 17.371164321899414, 'learning_rate': 1.4088888888888891e-05, 'epoch': 2.24}
{'loss': 0.077, 'grad_norm': 0.05183270201086998, 'learning_rate': 1.334814814814815e-05, 'epoch': 2.28}
{'loss': 0.0804, 'grad_norm': 0.03741835430264473, 'learning_rate': 1.2607407407407406e-05, 'epoch': 2.32}
{'loss': 0.0725, 'grad_norm': 2.293734312057495, 'learning_rate': 1.1866666666666668e-05, 'epoch': 2.36}
{'loss': 0.0949, 'grad_norm': 21.41135597229004, 'learning_rate': 1.1125925925925928e-05, 'epoch': 2.4}
{'loss': 0.0913, 'grad_norm': 0.8384788036346436, 'learning_rate': 1.0385185185185186e-05, 'epoch': 2.44}
{'loss': 0.0659, 'grad_norm': 0.036950141191482544, 'learning_rate': 9.644444444444444e-06, 'epoch': 2.48}
{'loss': 0.0453, 'grad_norm': 0.07896170765161514, 'learning_rate': 8.903703703703704e-06, 'epoch': 2.52}
{'loss': 0.0604, 'grad_norm': 0.049083225429058075, 'learning_rate': 8.162962962962964e-06, 'epoch': 2.56}
{'loss': 0.0677, 'grad_norm': 0.030093031004071236, 'learning_rate': 7.422222222222222e-06, 'epoch': 2.6}
{'loss': 0.0535, 'grad_norm': 0.05390451103448868, 'learning_rate': 6.681481481481482e-06, 'epoch': 2.64}
{'loss': 0.0438, 'grad_norm': 3.618467330932617, 'learning_rate': 5.940740740740741e-06, 'epoch': 2.68}
{'loss': 0.0967, 'grad_norm': 0.02307675965130329, 'learning_rate': 5.2e-06, 'epoch': 2.72}
{'loss': 0.0533, 'grad_norm': 0.04482545703649521, 'learning_rate': 4.459259259259259e-06, 'epoch': 2.76}
{'loss': 0.0354, 'grad_norm': 0.03384288772940636, 'learning_rate': 3.7185185185185185e-06, 'epoch': 2.8}
{'loss': 0.0344, 'grad_norm': 18.75791358947754, 'learning_rate': 2.977777777777778e-06, 'epoch': 2.84}
{'loss': 0.1158, 'grad_norm': 0.02878604829311371, 'learning_rate': 2.2370370370370373e-06, 'epoch': 2.88}
{'loss': 0.0627, 'grad_norm': 0.0344451367855072, 'learning_rate': 1.4962962962962962e-06, 'epoch': 2.92}
{'loss': 0.0733, 'grad_norm': 8.78803825378418, 'learning_rate': 7.555555555555556e-07, 'epoch': 2.96}
{'loss': 0.0773, 'grad_norm': 12.229208946228027, 'learning_rate': 1.4814814814814816e-08, 'epoch': 3.0}
{'eval_loss': 0.41186025738716125, 'eval_accuracy': 0.9144, 'eval_f1': 0.9141940657578188, 'eval_runtime': 4.738, 'eval_samples_per_second': 527.65, 'eval_steps_per_second': 16.674, 'epoch': 3.0}
{'train_runtime': 550.4846, 'train_samples_per_second': 108.995, 'train_steps_per_second': 6.812, 'train_loss': 0.19823516540527344, 'epoch': 3.0}
Val metrics: {'eval_loss': 0.4118654429912567, 'eval_accuracy': 0.914, 'eval_f1': 0.9138276553106213, 'eval_runtime': 4.6763, 'eval_samples_per_second': 534.608, 'eval_steps_per_second': 16.894, 'epoch': 3.0}
Test metrics: {'eval_loss': 0.45255526900291443, 'eval_accuracy': 0.902, 'eval_f1': 0.9024293110314616, 'eval_runtime': 4.8285, 'eval_samples_per_second': 517.758, 'eval_steps_per_second': 16.361, 'epoch': 3.0}
Evaluation metrics saved to: /home/comp/zhanzhao/comp7015-group/bert/result/distilbert-base-uncased-20251121-054637.json
Total epochs recorded: 3
Training completed!
Validation accuracy: 0.914
Test accuracy: 0.902
==========================================
DistilBert training test completed!
==========================================
